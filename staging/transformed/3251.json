{"location": {"country": "US", "locality": "Pleasanton", "region": "Pleasanton", "postal_code": "94588", "street_address": null, "latitude": 37.658436, "longitude": -121.877}, "salary": {"currency": null, "min_value": null, "max_value": null, "unit": null}, "job": {"title": "Machine Learning Engineer", "industry": "Information Technology and Services", "description": "Position:\u00a0AI/ML Engineer\nLocation:\u00a0Pleasanton, CA\nDuration:\u00a012 Months Contract with Extendable\nJob Description\nThe\nAI/ML Engineer\nshall lead the Artificial Intelligence/Machine Learning Modeling and Engineering team.\u00a0The consultant will play the role of technical lead and provide professional services to support the long term IT strategy and planning to include high level analysis, professional reports and presentations, and mentoring, support and training.\nThe tasks for the AI/ML Engineer include, but are not limited to, the following:\nProvide technical leadership, develop vision, gather requirements and translate client user requirements into technical architecture.\nDesign, build and scale Machine Learning systems across multiple domains.\nDesign and implement NLP algorithms\nDesign and implement an integrated Big Data platform and analytics solution\nDesign and implement data collectors to collect and transport data to the Big Data Platform.\nTECHNICAL KNOWLEDGE AND SKILLS\n:\nConsultant resources shall possess most of the following technical knowledge and experience:\nProvide technical leadership, develop vision, gather requirements and translate client user requirements into technical architecture.\nStrong Background in Statistical modeling, NLP and Machine Learning.\nExpertise in various facets of ML and NLP, such as classification, feature engineering, information extraction, clustering, semi-supervised learning, topic modeling and ranking.\nStrong Hands-on Experience in building, deploying and productionizing ML models using software such as Spark MLLib, TensorFlow, PyTorch, Python Scikit-learn etc. is mandatory\nAbility to evaluate and choose best suited ML algorithms, perform feature engineering and optimize Machine Learning Models is mandatory\nStrong fundamentals in algorithms, data structures, statistics, predictive modeling, & distributed systems is must\nStrong Experience with Data Science Notebooks like RStudio, Jupyter, Zeppelin, PyCharm etc.\nDesign and implement an integrated Big Data platform and analytics solution\nDesign and implement data collectors to collect and transport data to the Big Data Platform.\nGood to have but not mandatory 4+ years of hands-on Development, Deployment and production Support experience in Hadoop environment.\n4-5 years of programming experience in Java, Scala, Python.\nProficient in SQL and relational database design and methods for data retrieval.\nGood to have but not mandatory building data pipelines using Hadoop components Sqoop, Hive, Spark, Spark SQL, HBase.\nGood to have but not mandatory experience with developing Hive QL, UDF\u2019s for analyzing semi structured/structured datasets.\nGood to have but not mandatory experience ingesting and processing various file formats like Avro/Parquet/Sequence Files/Text Files etc.\nHands-on experience working in Real-Time analytics like Spark/Kafka/Storm\nMust have working experience in the data warehousing and Business Intelligence systems.\nExpertise in Unix/Linux environment in writing scripts and schedule/execute jobs.\nSuccessful track record of building automation scripts/code using Java, Bash, Python etc. and experience in production support issue resolution process.\nMUST HAVE SKILLS:\nMachine Learning, Deep Learning, NLP\nTensorFlow, Scipy, PyTorch, OpenCV, OCR\nNumpy, SKlearn, Pandas\nPython, Spark, Hive, SQL\nProductionize model", "employment_type": "CONTRACTOR", "date_posted": "2021-08-05T18:27:21.000Z"}, "company": {"name": "Saicon", "link": "https://www.linkedin.com/company/saicon"}, "education": {"required_credential": "bachelor degree"}, "experience": {"months_of_experience": 48, "seniority_level": "Mid-Level"}}